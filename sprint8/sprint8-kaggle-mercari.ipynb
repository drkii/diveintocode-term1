{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIF_sprint8-mercari-kaggle\n",
    "\n",
    "## 問題の理解\n",
    "\n",
    "### 目的\n",
    "\n",
    "メルカリの販売済み出品データを使って、適切な販売価格を提示するアルゴリズムを作成する。\n",
    "\n",
    "### 問題\n",
    "回帰\n",
    "評価関数：RMSLE(価格に1加算し対数を取った値の平均二乗和誤差)\n",
    "\n",
    "\n",
    "\n",
    "[メルカリのコンペ](https://www.kaggle.com/c/mercari-price-suggestion-challenge)\n",
    "\n",
    "### 概要\n",
    "\n",
    "本当の価値がいくらかを知るのは難しい。細かいところがちょっと変わるだけで大きな違いがある。\n",
    "\n",
    "今のオンライン販売の状況をみるにどんどん規模が大きくなっているし、\n",
    "服の価格一つとっても季節やブランドによってガラッと変わる。\n",
    "家電製品は新製品が出てスペックが相対的に落ちると価格に反映される。\n",
    "\n",
    "日本のユニコーン企業であるメルカリは価格付けについてよく知っている。\n",
    "\n",
    "メルカリは出品者に売れそうな価格帯を提示したいがなかなかタフだ。\n",
    "なぜなら元にする商品データは出品者が好き勝手かけるからです。\n",
    "\n",
    "このコンペでは適切な商品価格を自動的につけるアルゴリズムをつくることが目的です。\n",
    "\n",
    "提供されるデータは製品のカテゴリ名、ブランド名、品目条件などの詳細を含む、ユーザーが入力した製品のテキストの説明です。\n",
    "\n",
    "※注意　このデータの性質上このコンペはカーネルだけのコンペです。\n",
    "\n",
    "ファイルはカーネルを通じてのみ利用可能で、新しいデータに対応してアプローチを修正することはできません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc # ガベージコレクションを用意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= '../input/'\n",
    "\n",
    "train_df = pd.read_csv(path + 'train.tsv', sep='\\t', encoding='utf-8')\n",
    "test_df = pd.read_csv(path+'test.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "商品名、カテゴリーデータ、ブランド名、商品説明欄は文字列となっていて**自然言語処理**が必要となる。\n",
    "\n",
    "商品説明欄には**No description yet**、つまり説明無しもあるためこれは言葉としてではなく空文字で扱うなど注意が必要な事が分かる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_id             82489\n",
       "name                 82489\n",
       "item_condition_id    82489\n",
       "category_name        81867\n",
       "brand_name           45116\n",
       "price                82489\n",
       "shipping             82489\n",
       "item_description     82489\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['item_description'] == \"No description yet\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際にNo description yetは8万2489件あります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_id                  0\n",
       "name                      0\n",
       "item_condition_id         0\n",
       "category_name          6327\n",
       "brand_name           632682\n",
       "price                     0\n",
       "shipping                  0\n",
       "item_description          4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "欠損値は商品説明欄、カテゴリー名、ブランド名で見られる。\n",
    "\n",
    "それぞれの項目は以下の通り。\n",
    "- train_id リストのID\n",
    "- name 商品名\n",
    "- item_condition_id　商品の状態 　\n",
    "    - 新品、未使用\n",
    "    - 未使用に近い\n",
    "    - 目立った傷や汚れなし\n",
    "    - やや傷や汚れあり\n",
    "    - 傷や汚れあり\n",
    "    - 全体的に状態がわるい\n",
    "- category_name    カテゴリー \n",
    "    - 例「本・音楽・ゲーム」->「テレビゲーム」-「家庭用ゲーム本体」\n",
    "- brand_name   ブランド名\n",
    "- price  価格　\n",
    "    - 販売価格は実際に販売された価格　USD単位で今回の目的変数\n",
    "- shipping  送料どっち負担か？　出荷手数料が売り手によって支払われる場合は1、買い手によって支払われる場合は0\n",
    "- item_description  商品の説明欄\n",
    "\n",
    "価格に関する情報が入っている場合は**rm**に変換されている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_id             1482535\n",
       "name                 1225273\n",
       "item_condition_id          5\n",
       "category_name           1287\n",
       "brand_name              4809\n",
       "price                    828\n",
       "shipping                   2\n",
       "item_description     1281426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今のアプリで確認すると商品の状態は６段階だがUS版は５段階のようです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_condition_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.340890e+05</td>\n",
       "      <td>18.499444</td>\n",
       "      <td>0.491111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.772671e+05</td>\n",
       "      <td>17.256780</td>\n",
       "      <td>0.472034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.504571e+05</td>\n",
       "      <td>15.844483</td>\n",
       "      <td>0.434534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.384035e+05</td>\n",
       "      <td>13.100775</td>\n",
       "      <td>0.403101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.277316e+06</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       train_id      price  shipping\n",
       "item_condition_id                                   \n",
       "1                  7.340890e+05  18.499444  0.491111\n",
       "2                  7.772671e+05  17.256780  0.472034\n",
       "3                  7.504571e+05  15.844483  0.434534\n",
       "4                  8.384035e+05  13.100775  0.403101\n",
       "5                  1.277316e+06   5.000000  1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['category_name']=='Kids/Girls 0-24 Mos/Shoes'].groupby(['item_condition_id']).agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_condition_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>715599.378995</td>\n",
       "      <td>17.181996</td>\n",
       "      <td>0.525114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>735135.971497</td>\n",
       "      <td>16.883581</td>\n",
       "      <td>0.423926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>745969.350545</td>\n",
       "      <td>15.452381</td>\n",
       "      <td>0.483649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>809090.604790</td>\n",
       "      <td>13.919162</td>\n",
       "      <td>0.464072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>936581.625000</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_id      price  shipping\n",
       "item_condition_id                                    \n",
       "1                  715599.378995  17.181996  0.525114\n",
       "2                  735135.971497  16.883581  0.423926\n",
       "3                  745969.350545  15.452381  0.483649\n",
       "4                  809090.604790  13.919162  0.464072\n",
       "5                  936581.625000  13.750000  0.125000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['category_name'].fillna('nan').str.contains('Books')].groupby(['item_condition_id']).agg('mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "いくつかカテゴリーを絞って見てみると商品状態IDが小さい方が販売価格が大きいことが分かる。\n",
    "\n",
    "このため１が「新品、未使用」で５が「全体的に悪い」だと推測できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df, test_df\n",
    "gc.collect()\n",
    "train_df = pd.read_csv(path + 'train.tsv', sep='\\t', encoding='utf-8', nrows = 1000)\n",
    "test_df = pd.read_csv(path+'test.tsv', sep='\\t', encoding='utf-8', nrows = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロトタイプ実装のためここからはデータ量を削減して作業を行った。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前処理の実装と説明\n",
    "\n",
    "今回前処理として下記を行った。\n",
    "\n",
    "- 欠損値を埋める\n",
    "- 商品説明欄の'No description yet'は空欄の場合挿入されるワードなのでこれは空白文字に置き換える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量エンジニアリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値埋める\n",
    "train_df['item_condition_id'].fillna(2, inplace=True)\n",
    "test_df['item_condition_id'].fillna(2, inplace=True)\n",
    "train_df['shipping'].fillna(0, inplace=True)\n",
    "test_df['shipping'].fillna(0, inplace=True)\n",
    "\n",
    "# 説明欄の補正\n",
    "train_df['item_description'].fillna('', inplace=True)\n",
    "train_df['item_description'] = train_df['item_description'].replace('No description yet', '')\n",
    "test_df['item_description'].fillna('', inplace=True)\n",
    "test_df['item_description'] = test_df['item_description'].replace('No description yet', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS1 説明欄の３文字以上の単語数をカウントする　num_words_item_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 商品説明欄の単語数をカウントする\n",
    "def create_count_features(df_data):\n",
    "    def lg(text):\n",
    "        text = [x for x in text.split() if len(x) >= 3]\n",
    "        return len(text)\n",
    "\n",
    "    df_data['num_words_item_description'] = df_data['item_description'].apply(lg).astype(np.uint16)\n",
    "    return df_data\n",
    "train_df = create_count_features(train_df)\n",
    "test_df = create_count_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS2 メインカテゴリーのカウントベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def concat_train_test(train,test):\n",
    "# trainとtestのidカラム名を変更する\n",
    "    train = train.rename(columns = {'train_id':'id'})\n",
    "    test = test.rename(columns = {'test_id':'id'})\n",
    "\n",
    "    # 両方のセットへ「is_train」のカラムを追加\n",
    "    # 1 = trainのデータ、0 = testデータ\n",
    "    train['is_train'] = 1\n",
    "    test['is_train'] = 0\n",
    "\n",
    "    # trainのprice(価格）以外のデータをtestと連結\n",
    "    train_test_combine = pd.concat([train.drop(['price'], axis=1),test],axis=0)\n",
    "    return train_test_combine\n",
    "\n",
    "def split_cat(text):\n",
    "    # textを'/'で区切る\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "\n",
    "\n",
    "def item_des(df):\n",
    "    df['general_cat'], df['subcat_1'], df['subcat_2'] = \\\n",
    "    zip(*df['category_name'].apply(lambda x: split_cat(x)))\n",
    "    return df\n",
    "\n",
    "def to_categorical(df):\n",
    "    df['general_cat'] = df['general_cat'].astype('category')\n",
    "    df['subcat_1'] = df['subcat_1'].astype('category')\n",
    "    df['subcat_2'] = df['subcat_2'].astype('category')\n",
    "    df['item_condition_id'] = df['item_condition_id'].astype('category')\n",
    "    return df\n",
    "\n",
    "\n",
    "def CV(df, length):\n",
    "    \n",
    "    cv = CountVectorizer(min_df=5)\n",
    "    cv.fit(df['general_cat'])\n",
    "    X_train_category1 = cv.transform(df['general_cat'][:length])\n",
    "    X_test_category1 = cv.transform(df['general_cat'][length:])\n",
    "\n",
    "    return X_train_category1,X_test_category1\n",
    "\n",
    "def get_main_category(train,test):\n",
    "    len_train = len(train)\n",
    "    concat_df = concat_train_test(train, test)\n",
    "    concat_df = item_des(concat_df)\n",
    "    concat_df = to_categorical(concat_df)\n",
    "    train_cat1, test_cat1 = CV(concat_df, len_train)\n",
    "\n",
    "    return train_cat1, test_cat1\n",
    "\n",
    "train_cat1, test_cat1 = get_main_category(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FS3 商品説明欄のカウントベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def concat_train_test(train,test):\n",
    "# trainとtestのidカラム名を変更する\n",
    "    train = train.rename(columns = {'train_id':'id'})\n",
    "    test = test.rename(columns = {'test_id':'id'})\n",
    "\n",
    "    # 両方のセットへ「is_train」のカラムを追加\n",
    "    # 1 = trainのデータ、0 = testデータ\n",
    "    train['is_train'] = 1\n",
    "    test['is_train'] = 0\n",
    "\n",
    "    # trainのprice(価格）以外のデータをtestと連結\n",
    "    train_test_combine = pd.concat([train.drop(['price'], axis=1),test],axis=0)\n",
    "    return train_test_combine\n",
    "\n",
    "def item_des_tfidf(df,length):\n",
    "    tv = TfidfVectorizer(max_features=1000,\n",
    "                             ngram_range=(1, 3),\n",
    "                             stop_words='english')\n",
    "    tv.fit(df['item_description'])\n",
    "\n",
    "    X_description = tv.transform(df['item_description'])\n",
    "    X_train_description = tv.transform(df['item_description'][:length])\n",
    "    X_test_description = tv.transform(df['item_description'][length:])\n",
    "\n",
    "    return X_train_description,X_test_description\n",
    "\n",
    "def get_X_description(train,test):\n",
    "    len_train = len(train)\n",
    "    concat_df = concat_train_test(train, test)\n",
    "    train_description, test_description = item_des_tfidf(concat_df, len_train)\n",
    "\n",
    "    return train_description, test_description\n",
    "\n",
    "train_item_description, test_item_description = get_X_description(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack, vstack\n",
    "\n",
    "use_cols = ['item_condition_id', 'shipping', 'num_words_item_description']\n",
    "X_train = train_df[use_cols]\n",
    "y_train = train_df['price'].values\n",
    "X_test = test_df[use_cols]\n",
    "if PRODOCTION == False:\n",
    "    y_test = test_df['price'].values\n",
    "\n",
    "# sparse_matrix化 カウントベクトル系の特徴量を追加\n",
    "X_train = hstack((X_train, train_cat1, train_item_description)).tocsr()\n",
    "X_test = hstack((X_test, test_cat1, test_item_description)).tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [注意]ここまででX_train,X_testは特徴量エンジニアリングした項目と合わせてsparse_matrixにしておく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error \n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# 評価関数を定義\n",
    "def root_mean_squared_log_error(truth, pred):\n",
    "    error = np.log1p(truth) - np.log1p(pred)\n",
    "    return np.sqrt(np.sum(error*error)/ len(truth) )\n",
    "\n",
    "rmsle = make_scorer(root_mean_squared_log_error, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.LinearModel リッジ回帰での学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# リッジ回帰で学習\n",
    "###################\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model_ridge = Ridge(alpha=20)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = model_ridge.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交差検証\n",
    "\n",
    "例としてリッジ回帰のみの交差検証。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8464497611479546\n",
      "0.833194791143947\n",
      "0.7840237702365039\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    cv_X_train, cv_X_test = X_train[train_index], X_train[test_index]\n",
    "    cv_y_train, cv_y_test = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    model_ridge = Ridge(alpha=20)\n",
    "    model_ridge.fit(cv_X_train, cv_y_train)\n",
    "    print(root_mean_squared_log_error(cv_y_test, model_ridge.predict(cv_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.GBM:XGBoostモデルでの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# XGBoostで学習させてみる\n",
    "###################\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# 動かすパラメータを明示的に表示\n",
    "params = {\n",
    "    \"learning_rate\":[0.05,0.1],\n",
    "    \"max_depth\": [2,3,5],\n",
    "    \"subsample\":[0.5,0.8,0.9,1],\n",
    "    \"colsample_bytree\": [0.5,1.0],\n",
    "}\n",
    "\n",
    "params = {\n",
    "                # Feiyang: 10. 把 7 改成了 8\n",
    "                'num_leaves': 2 ** 8 - 1,\n",
    "                'objective': 'regression_l2',\n",
    "                # Feiyang: 11. 把 8 改成了 9\n",
    "                'max_depth': 9,\n",
    "                'min_data_in_leaf': 50,\n",
    "                # Feiyang: 12. 把 0.01 改成了 0.007 并同时改了下面的 Num_round 和 early_stopping_rounds\n",
    "                'learning_rate': 0.007,\n",
    "                'feature_fraction': 0.6,\n",
    "                # Feiyang: 13. 把 0.75 改成了 0.8\n",
    "                'bagging_fraction': 0.8,\n",
    "                'bagging_freq': 1,\n",
    "                'metric': 'rmse',\n",
    "                'num_threads': 4,\n",
    "                'seed': 2018,\n",
    "            }\n",
    "\n",
    "# モデルにインスタンス生成\n",
    "model = xgb.XGBRegressor()\n",
    "# ハイパーパラメータ探索\n",
    "cv = GridSearchCV(model, params, cv = 3, scoring=rmsle) \n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "if PRODOCTION==False:\n",
    "    print(root_mean_squared_log_error(y_test, cv.predict(X_test)))\n",
    "\n",
    "y_pred_xgb = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.アンサンブル（予測値の平均）\n",
    "\n",
    "一番簡単な方法で予測値の合計をモデル数で割る。\n",
    "コードは下記の通りだが、今回は採用せず、４のスタッキングで最終的な予測値を出力する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_array = np.c_[y_pred_ridge, y_pred_xgb]\n",
    "y_pred_ensemble = np.average(y_pred_array, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. スタッキング（XGBoost）\n",
    "\n",
    "検証は下記のように行う。\n",
    "\n",
    "1. 訓練データをn分割し、n-1が訓練データ、1がテストデータとする。\n",
    "2. それぞれの分割に対して、各モデルで学習、予測を行う。\n",
    "3. 各モデルが予測した出力を説明変数としてXGBoostで学習する。\n",
    "\n",
    "\n",
    "> [参考](http://segafreder.hatenablog.com/entry/2016/05/24/235822)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'n_estimators': 50} -0.07441824488856552\n",
      "Ridge回帰：0.8464474511314641\n",
      "XGBoost：0.8869277746238913\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'n_estimators': 50} -0.1833287294720582\n",
      "Ridge回帰：0.8332148417389875\n",
      "XGBoost：0.8709576674468583\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "{'max_depth': 2, 'n_estimators': 50} -0.2612983780989679\n",
      "Ridge回帰：0.7840364494834698\n",
      "XGBoost：0.8148636252475677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    6.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "######################\n",
    "# STEP1 : 2モデルでの学習\n",
    "######################\n",
    "\n",
    "score_ridge_list = []\n",
    "score_xgb_list = []\n",
    "\n",
    "predict = np.zeros((y_train.shape[0], 2))\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    cv_X_train, cv_X_test = X_train[train_index], X_train[test_index]\n",
    "    cv_y_train, cv_y_test = y_train[train_index], y_train[test_index]\n",
    "\n",
    "    # Ridge回帰\n",
    "    model_ridge = Ridge(alpha=20)\n",
    "    model_ridge.fit(cv_X_train, cv_y_train)\n",
    "    y_predict_ridge = model_ridge.predict(cv_X_test)\n",
    "\n",
    "    # xgboostモデルの作成\n",
    "    reg = xgb.XGBRegressor()\n",
    "\n",
    "    # ハイパーパラメータ探索\n",
    "    reg_cv = GridSearchCV(reg, {'max_depth': [2,4,6], 'n_estimators': [50,100,200]}, verbose=1)\n",
    "    reg_cv.fit(cv_X_train, cv_y_train)\n",
    "    print(reg_cv.best_params_, reg_cv.best_score_)\n",
    "\n",
    "    # 改めて最適パラメータで学習\n",
    "    model_xgb = xgb.XGBRegressor(**reg_cv.best_params_)\n",
    "    model_xgb.fit(cv_X_train, cv_y_train)\n",
    "    y_predict_xgb = model_xgb.predict(cv_X_test)\n",
    "    \n",
    "    score_ridge = root_mean_squared_log_error(cv_y_test, y_predict_ridge)\n",
    "    score_xgb = root_mean_squared_log_error(cv_y_test, y_predict_xgb)\n",
    "    \n",
    "    score_ridge_list.append(score_ridge)\n",
    "    score_xgb_list.append(score_xgb)\n",
    "    \n",
    "    print(\"Ridge回帰：{}\".format(score_ridge))\n",
    "    print(\"XGBoost：{}\".format(score_xgb))\n",
    "    \n",
    "    predict[test_index, 0] = y_predict_ridge\n",
    "    predict[test_index, 1]= y_predict_xgb    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x1a40432198>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kzfm/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/xgboost/core.py\", line 366, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'n_estimators': 50} -0.12414173972858455\n",
      "スタッキング：0.8390638344996908\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'n_estimators': 50} -0.12414173972858455\n",
      "スタッキング：1.0960539597494117\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "{'max_depth': 2, 'n_estimators': 50} -0.12414173972858455\n",
      "スタッキング：0.7813018558939326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    8.0s finished\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# STEP2 : 予測値を説明変数とした学習でスコアを検証\n",
    "######################\n",
    "\n",
    "score_stacking_list = []\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "for train_index, test_index in kf.split(predict):\n",
    "    cv_X_train, cv_X_test = predict[train_index, :], predict[test_index, :]\n",
    "    cv_y_train, cv_y_test = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    # xgboostモデルの作成\n",
    "    reg = xgb.XGBRegressor()\n",
    "\n",
    "    # ハイパーパラメータ探索\n",
    "    reg_cv = GridSearchCV(reg, {'max_depth': [2,4,6], 'n_estimators': [50,100,200]}, verbose=1)\n",
    "    reg_cv.fit(X_train, y_train)\n",
    "    print(reg_cv.best_params_, reg_cv.best_score_)\n",
    "\n",
    "    # 改めて最適パラメータで学習\n",
    "    model_xgb = xgb.XGBRegressor(**reg_cv.best_params_)\n",
    "    model_xgb.fit(cv_X_train, cv_y_train)\n",
    "    y_predict_stacking = model_xgb.predict(cv_X_test)\n",
    "    \n",
    "    score = root_mean_squared_log_error(cv_y_test, y_predict_stacking)\n",
    "    print(\"スタッキング：{}\".format(score))\n",
    "    score_stacking_list.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE      score: 0.8212329141179738\n",
      "XGB         score: 0.8575830224394392\n",
      "Staking   score: 0.905473216714345\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# STEP3 : スコアを確認する\n",
    "######################\n",
    "\n",
    "print(\"RIDGE      score:\", np.average(score_ridge_list))\n",
    "print(\"XGB         score:\", np.average(score_xgb_list))\n",
    "print(\"Staking   score:\", np.average(score_stacking_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よければ全訓練データで学習してテストデータを予測する。\n",
    "\n",
    "1000件データでスコアが上昇していないが、スコアが上がったとして進める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# スタッキングで学習\n",
    "######################\n",
    "\n",
    "# Ridge回帰\n",
    "model_ridge = Ridge(alpha=20)\n",
    "model_ridge.fit(X_train, y_train)\n",
    "y_predict_ridge = model_ridge.predict(X_test)\n",
    "\n",
    "# xgboostモデルの作成\n",
    "reg = xgb.XGBRegressor()\n",
    "\n",
    "# ハイパーパラメータ探索\n",
    "# reg_cv = GridSearchCV(reg, {'max_depth': [2,4,6], 'n_estimators': [50,100,200]}, verbose=1)\n",
    "# reg_cv.fit(cv_X_train, cv_y_train)\n",
    "# print(reg_cv.best_params_, reg_cv.best_score_)\n",
    "\n",
    "# XGBoostモデルで学習\n",
    "model_xgb = xgb.XGBRegressor(**reg_cv.best_params_)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_predict_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "# テストデータの予測値を説明変数とする\n",
    "y_predict_two_modle = np.array([y_predict_ridge, y_predict_xgb]).T\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(**reg_cv.best_params_)\n",
    "model_xgb.fit(predict, y_train)\n",
    "y_predict_stacking = model_xgb.predict(y_predict_two_modle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測値を提出ファイルに出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysubmission=pd.DataFrame()\n",
    "mysubmission['test_id']=test_df['test_id']\n",
    "mysubmission['price'] = y_predict_stacking\n",
    "mysubmission.to_csv('ensemble.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パイプライン化\n",
    "\n",
    "前処理部分、特徴量エンジニアリング部分をモジュール化した。\n",
    "\n",
    "メインファイル　sprint8_main.py\n",
    "\n",
    "mercariディレクトリに下記の４ファイルを配置します。\n",
    "\n",
    "- 説明欄の単語数（３文字以上）カウント：create_count_feature.py\n",
    "- メインカテゴリーのカウントベクトル化：get_main_category.py\n",
    "- 説明欄のカウントベクトル化：item_des_feature.py\n",
    "- ブランド名のダミー変数：create_count_feature.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## メモリ管理\n",
    "\n",
    "今回のようにsparse matrixを使ったり、大規模なデータを扱う際にはメモリ使用量に気をつけながら開発を行う必要がある。\n",
    "\n",
    "**memory_profiler**を導入すると現在のメモリ使用量や変数がどれくらいメモリを使っているかが分かる。\n",
    "\n",
    "pip install memory_profiler\n",
    "\n",
    "\n",
    "### 1. astype('np.uint16')などで型を小さくする。\n",
    "\n",
    "pd.read_csvは数値型のデータはint64型を確保してしまう。\n",
    "そのため型や数値の最小、最大値を確認して適切な型を指定するとメモリの使用を抑えられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(path+'test.tsv', sep='\\t', encoding='utf-8' , nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id               int64\n",
       "name                 object\n",
       "item_condition_id     int64\n",
       "category_name        object\n",
       "brand_name           object\n",
       "shipping              int64\n",
       "item_description     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Breast cancer \"I fight like a girl\" ring</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Rings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Size 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers</td>\n",
       "      <td>1</td>\n",
       "      <td>Other/Office supplies/Shipping Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coach bag</td>\n",
       "      <td>1</td>\n",
       "      <td>Vintage &amp; Collectibles/Bags and Purses/Handbag</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new coach bag. Bought for [rm] at a Coac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Floral Kimono</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Sweaters/Cardigan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-floral kimono -never worn -lightweight and pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Life after Death</td>\n",
       "      <td>3</td>\n",
       "      <td>Other/Books/Religion &amp; Spirituality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Rediscovering life after the loss of a loved o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                      name  item_condition_id  \\\n",
       "0        0  Breast cancer \"I fight like a girl\" ring                  1   \n",
       "1        1  25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers                  1   \n",
       "2        2                                 Coach bag                  1   \n",
       "3        3                             Floral Kimono                  2   \n",
       "4        4                          Life after Death                  3   \n",
       "\n",
       "                                    category_name brand_name  shipping  \\\n",
       "0                             Women/Jewelry/Rings        NaN         1   \n",
       "1         Other/Office supplies/Shipping Supplies        NaN         1   \n",
       "2  Vintage & Collectibles/Bags and Purses/Handbag      Coach         1   \n",
       "3                         Women/Sweaters/Cardigan        NaN         0   \n",
       "4             Other/Books/Religion & Spirituality        NaN         1   \n",
       "\n",
       "                                    item_description  \n",
       "0                                             Size 7  \n",
       "1  25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...  \n",
       "2  Brand new coach bag. Bought for [rm] at a Coac...  \n",
       "3  -floral kimono -never worn -lightweight and pe...  \n",
       "4  Rediscovering life after the loss of a loved o...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回はshippingに着目する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['shipping'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['shipping'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id               int64\n",
       "name                 object\n",
       "item_condition_id     int64\n",
       "category_name        object\n",
       "brand_name           object\n",
       "shipping              uint8\n",
       "item_description     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['shipping'] = sample_df['shipping'].astype('uint8')\n",
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "型が変更された。このように数値型のデータは贅沢にメモリを使うので注意する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. read_csvでdtypeを指定　\n",
    "\n",
    "データ型が予め分かっている場合はread_csv時に型を指定することができる。\n",
    "データの内容を確認した後はこの方法でメモリを削減できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "test_id               int64\n",
       "name                 object\n",
       "item_condition_id     uint8\n",
       "category_name        object\n",
       "brand_name           object\n",
       "shipping              uint8\n",
       "item_description     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = pd.read_csv(path+'test.tsv', sep='\\t', encoding='utf-8' , nrows=10, dtype={'item_condition_id': 'uint8', 'shipping': 'uint8'})\n",
    "sample_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. read_csvでchunksize指定して指定データ数でループさせる\n",
    "\n",
    "データ数を制限して実行できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 7)\n",
      "(80000, 7)\n",
      "(80000, 7)\n",
      "(80000, 7)\n",
      "(80000, 7)\n",
      "(80000, 7)\n",
      "(80000, 7)\n",
      "(80000, 7)\n",
      "(53359, 7)\n"
     ]
    }
   ],
   "source": [
    "for df_submission in pd.read_csv(path+'test.tsv', sep='\\t', encoding='utf-8' , chunksize=80000):\n",
    "    print(df_submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. ガベージコレクションで使用し終わった変数を削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 703.46 MiB, increment: 0.18 MiB\n"
     ]
    }
   ],
   "source": [
    "memit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 868.23 MiB, increment: 164.77 MiB\n"
     ]
    }
   ],
   "source": [
    "memit train_df = pd.read_csv(path + 'train.tsv', sep='\\t', encoding='utf-8', nrows = 500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "１５０MBほど使用量が増えていることが分かる。\n",
    "\n",
    "変数を削除して、ガベージコレクションを使うとメモリを開放してくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function gc.collect>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train_df\n",
    "gc.collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 723.33 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "memit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモリ使用量が元に戻った。\n",
    "\n",
    "メモリ節約の方法はいくつかあるのでデータ量が多そうな場合は計測してどうするか考える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## マルチプロセッシング\n",
    "\n",
    "Grobal Interpreter Lock(GIL)\n",
    "1つのインタプリタ上で複数スレッドを同時実行されないようにして、スレッドセーフを木にする必要がなくなり通常の動作が高速になる。\n",
    "\n",
    "しかしこのままでは複数のCPUを積んでいていも同時に実行できるスレッドは常に一つに制限されてしまいハードを活かすことはできません。\n",
    "\n",
    "この制限を回避するために、標準ライブラリに**multiprocessing**というマルチプロセスを扱うライブラリがあります。\n",
    "\n",
    "> パーフェクトpython P35参照\n",
    "\n",
    "今回はテスト関数（ある項目値を２倍にする）の処理をマルチコアで行うような処理を記述してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "cores=2\n",
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, cores)\n",
    "    pool = Pool(cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_func(df):\n",
    "    print(df['test_id'].head())\n",
    "    print(df.shape)\n",
    "    print('')\n",
    "    df['item_condition_id'] = df['item_condition_id']*2 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "Name: test_id, dtype: int64500    500\n",
      "501    501\n",
      "502    502\n",
      "503    503\n",
      "504    504\n",
      "Name: test_id, dtype: int64\n",
      "\n",
      "(500, 7)\n",
      "(500, 7)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_df = pd.read_csv(path+'test.tsv', sep='\\t', encoding='utf-8' , nrows=1000)\n",
    "\n",
    "result_df = parallelize_dataframe(sample_df, test_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Breast cancer \"I fight like a girl\" ring</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Jewelry/Rings</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Size 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers</td>\n",
       "      <td>2</td>\n",
       "      <td>Other/Office supplies/Shipping Supplies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Coach bag</td>\n",
       "      <td>2</td>\n",
       "      <td>Vintage &amp; Collectibles/Bags and Purses/Handbag</td>\n",
       "      <td>Coach</td>\n",
       "      <td>1</td>\n",
       "      <td>Brand new coach bag. Bought for [rm] at a Coac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Floral Kimono</td>\n",
       "      <td>4</td>\n",
       "      <td>Women/Sweaters/Cardigan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-floral kimono -never worn -lightweight and pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Life after Death</td>\n",
       "      <td>6</td>\n",
       "      <td>Other/Books/Religion &amp; Spirituality</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Rediscovering life after the loss of a loved o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                      name  item_condition_id  \\\n",
       "0        0  Breast cancer \"I fight like a girl\" ring                  2   \n",
       "1        1  25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers                  2   \n",
       "2        2                                 Coach bag                  2   \n",
       "3        3                             Floral Kimono                  4   \n",
       "4        4                          Life after Death                  6   \n",
       "\n",
       "                                    category_name brand_name  shipping  \\\n",
       "0                             Women/Jewelry/Rings        NaN         1   \n",
       "1         Other/Office supplies/Shipping Supplies        NaN         1   \n",
       "2  Vintage & Collectibles/Bags and Purses/Handbag      Coach         1   \n",
       "3                         Women/Sweaters/Cardigan        NaN         0   \n",
       "4             Other/Books/Religion & Spirituality        NaN         1   \n",
       "\n",
       "                                    item_description  \n",
       "0                                             Size 7  \n",
       "1  25 pcs NEW 7.5\"x12\" Kraft Bubble Mailers Lined...  \n",
       "2  Brand new coach bag. Bought for [rm] at a Coac...  \n",
       "3  -floral kimono -never worn -lightweight and pe...  \n",
       "4  Rediscovering life after the loss of a loved o...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このようにコアにプロセスを割り振ってデータを集約することで複数コアを余すことなく使用することができる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
